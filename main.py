import streamlit as st
from crawler import NewsCrawler
from text_cleaner import TextCleaner
from model import NewsSummarizer
from Data_Manager import NewsUtils

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="3ì¤„ ë‰´ìŠ¤ ìš”ì•½ ë´‡", page_icon="ğŸ“°")

#ì´ˆê¸°í™”(ê°ì²´ ìƒì„±)
@st.cache_resource
def load_summarizer():
    return NewsSummarizer()

crawler = NewsCrawler()
cleaner = TextCleaner()
utils = NewsUtils()
summarizer = load_summarizer()

#í™”ë©´ êµ¬ì„± (UI)
st.title("ğŸ“° AI 3ì¤„ ë‰´ìŠ¤ ìš”ì•½ ë´‡")
st.markdown("ë„¤ì´ë²„ ë‰´ìŠ¤ URLì„ ì…ë ¥í•˜ë©´ **AIê°€ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½**í•´ì¤ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”: ì‚¬ìš©ë²• ì„¤ëª…
with st.sidebar:
    st.header("ì‚¬ìš© ë°©ë²•")
    st.markdown("1. ë„¤ì´ë²„ ë‰´ìŠ¤ì— ì ‘ì†í•œë‹¤.")
    st.markdown("2. ê¸°ì‚¬ ë§í¬(URL)ë¥¼ ë³µì‚¬í•œë‹¤.")
    st.markdown("3. ì…ë ¥ì°½ì— ë¶™ì—¬ë„£ê³  ë²„íŠ¼ì„ ëˆ„ë¥¸ë‹¤.")
    st.info("Team 5 Project : Open Source SW")

# URL ì…ë ¥ì°½
url = st.text_input("ë‰´ìŠ¤ ê¸°ì‚¬ URLì„ ì…ë ¥í•˜ì„¸ìš”:")

# ë²„íŠ¼ í´ë¦­ ì‹œ ë™ì‘
if st.button("ìš”ì•½ ì‹œì‘ ğŸš€"):
    if url:
        try:
            with st.spinner('1ë‹¨ê³„: ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤... ğŸ•·ï¸'):
                title, raw_content = crawler.get_news(url)
            
            if not title:
                st.error(raw_content) # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
            else:
                st.success(f"ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ: {title}")
                
                with st.spinner('2ë‹¨ê³„: ë‚´ìš©ì„ ë‹¤ë“¬ê³  AIê°€ ì½ëŠ” ì¤‘ì…ë‹ˆë‹¤... ğŸ§¹'):
                    clean_content = cleaner.clean_text(raw_content)
                
                # ë³¸ë¬¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ì›ë¬¸ ê¸°ì‚¬ ë‚´ìš© ë³´ê¸°"):
                    st.write(clean_content)

                if cleaner.is_valid_length(clean_content):
                    with st.spinner('3ë‹¨ê³„: AIê°€ ì—´ì‹¬íˆ ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤... ğŸ¤–'):
                        summary = summarizer.summarize(clean_content)
                    
                    #ê²°ê³¼ ì¶œë ¥
                    st.divider()
                    st.subheader("ğŸ“ 3ì¤„ ìš”ì•½ ê²°ê³¼")
                    st.info(summary)
                    
                    #í‚¤ì›Œë“œ ë¶„ì„
                    keywords = utils.extract_keywords(clean_content)
                    st.write("ğŸ”‘ **í•µì‹¬ í‚¤ì›Œë“œ:** ", ", ".join([f"#{k[0]}" for k in keywords]))
                    
                    #íŒŒì¼ ì €ì¥
                    saved_file = utils.save_to_csv(title, clean_content, summary)
                    st.caption(f"âœ… ê²°ê³¼ê°€ '{saved_file}' íŒŒì¼ì— ìë™ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    
                else:
                    st.warning("ê¸°ì‚¬ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì•„ì„œ ìš”ì•½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    else:
        st.warning("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")